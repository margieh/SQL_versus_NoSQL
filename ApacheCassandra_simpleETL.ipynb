{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I. ETL Pipeline for Pre-Processing the Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import Python packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import cassandra\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating list of filepaths to process original event csv data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/workspace/event_data/2018-11-27-events.csv', '/home/workspace/event_data/2018-11-04-events.csv', '/home/workspace/event_data/2018-11-07-events.csv', '/home/workspace/event_data/2018-11-09-events.csv', '/home/workspace/event_data/2018-11-19-events.csv', '/home/workspace/event_data/2018-11-05-events.csv', '/home/workspace/event_data/2018-11-22-events.csv', '/home/workspace/event_data/2018-11-16-events.csv', '/home/workspace/event_data/2018-11-26-events.csv', '/home/workspace/event_data/2018-11-24-events.csv', '/home/workspace/event_data/2018-11-29-events.csv', '/home/workspace/event_data/2018-11-15-events.csv', '/home/workspace/event_data/2018-11-20-events.csv', '/home/workspace/event_data/2018-11-06-events.csv', '/home/workspace/event_data/2018-11-18-events.csv', '/home/workspace/event_data/2018-11-21-events.csv', '/home/workspace/event_data/2018-11-10-events.csv', '/home/workspace/event_data/2018-11-23-events.csv', '/home/workspace/event_data/2018-11-02-events.csv', '/home/workspace/event_data/2018-11-28-events.csv', '/home/workspace/event_data/2018-11-03-events.csv', '/home/workspace/event_data/2018-11-13-events.csv', '/home/workspace/event_data/2018-11-30-events.csv', '/home/workspace/event_data/2018-11-12-events.csv', '/home/workspace/event_data/2018-11-01-events.csv', '/home/workspace/event_data/2018-11-14-events.csv', '/home/workspace/event_data/2018-11-25-events.csv', '/home/workspace/event_data/2018-11-08-events.csv', '/home/workspace/event_data/2018-11-17-events.csv', '/home/workspace/event_data/2018-11-11-events.csv']\n"
     ]
    }
   ],
   "source": [
    "filepath = os.getcwd() + '/event_data'\n",
    "\n",
    "for root, dirs, files in os.walk(filepath):\n",
    "    #skip jupyter notebook checkpoint files\n",
    "    if dirs != []:\n",
    "        file_path_list = glob.glob(os.path.join(root,'*'))\n",
    "        print(file_path_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Processing the files to create the data file csv that will be used for Apache Casssandra tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data_rows_list = []\n",
    "    \n",
    "for f in file_path_list:\n",
    "    with open(f, 'r', encoding = 'utf8', newline='') as csvfile: \n",
    "        csvreader = csv.reader(csvfile)\n",
    "        next(csvreader)   \n",
    "        for line in csvreader:\n",
    "            full_data_rows_list.append(line)\n",
    "            \n",
    "csv.register_dialect('myDialect', quoting=csv.QUOTE_ALL, skipinitialspace=True)\n",
    "\n",
    "with open('event_datafile_new.csv', 'w', encoding = 'utf8', newline='') as f:\n",
    "    writer = csv.writer(f, dialect='myDialect')\n",
    "    writer.writerow(['artist','firstName','gender','itemInSession','lastName','length',\\\n",
    "                'level','location','sessionId','song','userId'])\n",
    "    for row in full_data_rows_list:\n",
    "        #skip rows where artists is not provided\n",
    "        if (row[0] == ''):\n",
    "            continue\n",
    "        writer.writerow((row[0], row[2], row[3], row[4], row[5], row[6], row[7], row[8], row[12], row[13], row[16]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6821\n"
     ]
    }
   ],
   "source": [
    "with open('event_datafile_new.csv', 'r', encoding = 'utf8') as f:\n",
    "    print(sum(1 for line in f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II. Setup Apache Cassandra, define and execute required queries.\n",
    "\n",
    "## The CSV file titled <font color=red>event_datafile_new.csv</font>, located within the directory now contains the following columns: \n",
    "- artist \n",
    "- firstName of user\n",
    "- gender of user\n",
    "- item number in session\n",
    "- last name of user\n",
    "- length of the song\n",
    "- level (paid or free song)\n",
    "- location of the user\n",
    "- sessionId\n",
    "- song title\n",
    "- userId\n",
    "\n",
    "The image below is a screenshot of what the denormalized data should appear like in the <font color=red>**event_datafile_new.csv**</font> after the code above is run:<br>\n",
    "\n",
    "<img src=\"images/image_event_datafile_new.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cassandra.cluster import Cluster\n",
    "cluster = Cluster()\n",
    "\n",
    "session = cluster.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    session.execute(\n",
    "        \"CREATE KEYSPACE IF NOT EXISTS practice WITH REPLICATION = {'class' : 'SimpleStrategy','replication_factor': 1}\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create keyspace. Error message: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Keyspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    session.set_keyspace('practice')\n",
    "except Exception as e:\n",
    "    print(f\"Failed to set keyspace. Error message: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a generic error handling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error(query, e):\n",
    "    print(f\"Failed to execute query {query}. Error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create three queries that return data meeting the following requirements: \n",
    "1. Returns artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "2. Returns only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "3. Returns every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 1\n",
    "\n",
    "**Requirement**: Returns artist, song title and song's length in the music app history that was heard during  sessionId = 338, and itemInSession  = 4\n",
    "\n",
    "**Description:** Our PRIMARY KEY will consist of 'sessionID', which will be used as the PARTITIONING KEY allowing filtering of our data by this value, and 'itemInSession' which will be used as the CLUSTERING column, allowing the query to return the nth song of a given session sorted in DESC order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(keyspace_name='practice', table_name='sessions', column_name='artist', clustering_order='none', column_name_bytes=b'artist', kind='regular', position=-1, type='text')\n",
      "Row(keyspace_name='practice', table_name='sessions', column_name='iteminsession', clustering_order='asc', column_name_bytes=b'iteminsession', kind='clustering', position=0, type='int')\n",
      "Row(keyspace_name='practice', table_name='sessions', column_name='length', clustering_order='none', column_name_bytes=b'length', kind='regular', position=-1, type='decimal')\n",
      "Row(keyspace_name='practice', table_name='sessions', column_name='sessionid', clustering_order='none', column_name_bytes=b'sessionid', kind='partition_key', position=0, type='int')\n",
      "Row(keyspace_name='practice', table_name='sessions', column_name='song', clustering_order='none', column_name_bytes=b'song', kind='regular', position=-1, type='text')\n"
     ]
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS sessions \\\n",
    "        (sessionId int, itemInSession int, artist text, song text, length decimal, \\\n",
    "        PRIMARY KEY (sessionId, itemInSession))\"\n",
    "\n",
    "try: \n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    error(query, e)\n",
    "    \n",
    "\n",
    "query1 = \"SELECT * FROM system_schema.columns WHERE keyspace_name = 'practice' AND table_name = 'sessions'\"\n",
    "\n",
    "\n",
    "try: \n",
    "    rows = session.execute(query1)\n",
    "except Exception as e:\n",
    "    error(query1, e)\n",
    "\n",
    "for row in rows:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines added: 6820\n"
     ]
    }
   ],
   "source": [
    "file = 'event_datafile_new.csv'\n",
    "line_ct = 0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"\"\"INSERT INTO sessions (sessionId, itemInSession, artist, song, length)\"\"\"\n",
    "        query = query + \"\"\" VALUES (%s, %s, %s, %s, %s);\"\"\"\n",
    "        try: \n",
    "            session.execute(query, (int(line[8]), int(line[3]), line[0], line[9], float(line[5])))\n",
    "            line_ct +=1\n",
    "        except Exception as e:\n",
    "            print(line)\n",
    "            print(e)\n",
    "print(f\"lines added: {line_ct}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify that the data have been inserted into each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(artist='Faithless', song='Music Matters (Mark Knight Dub)', length=Decimal('495.3073'))\n"
     ]
    }
   ],
   "source": [
    "check_q1 = \"\"\"SELECT artist, song, length from sessions WHERE sessionId = 338 AND itemInSession = 4;\"\"\"\n",
    "try: \n",
    "    res = session.execute(check_q1)\n",
    "except Exception as e:\n",
    "    error(check_q1, e)\n",
    "    \n",
    "for r in res:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 2\n",
    "\n",
    "**Requirement**: Returns only the following: name of artist, song (sorted by itemInSession) and user (first and last name) for userid = 10, sessionid = 182\n",
    "\n",
    "**Description:** For this query, we'll create a COMPOSITE PARTITIONING KEY using 'userId' and 'sessionId'. This will allow rows to be uniquely identified (and filtered) by a combination of both columns. 'itemInSession' will be used as the CLUSTERING COLUMN allowing the query to return the nth song of a given session for a specific user. 'itemInSession' will be omitted from our query statement, to accomodate the requirement that our query returns **ONLY** the columns representing the artist's name, song title, and user identification details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines added: 6820\n"
     ]
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS user_sessions \\\n",
    "        (userId int, sessionId int, itemInSession int, lastName text, firstName text, artist text, song text, \\\n",
    "        PRIMARY KEY ((userId, sessionid), itemInSession));\"\n",
    "\n",
    "try: \n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    error(query, e)\n",
    "    \n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "line_ct = 0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"\"\"INSERT INTO user_sessions (userId, sessionId, itemInSession, lastName, firstName, artist, song)\"\"\"\n",
    "        query = query + \"\"\" VALUES (%s, %s, %s, %s, %s, %s, %s);\"\"\"\n",
    "        try: \n",
    "            session.execute(query, (int(line[3]), int(line[8]), int(line[3]), line[4], line[1], line[8], line[9],))\n",
    "            line_ct +=1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "print(f\"lines added: {line_ct}\")\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "check_q2 = \"\"\"SELECT userId, lastName, firstName, artist, song from user_sessions WHERE userId = 10 and sessionId = 182;\"\"\"\n",
    "\n",
    "try: \n",
    "    res = session.execute(check_q2)\n",
    "    if not res.current_rows:\n",
    "        print(\"None\")\n",
    "    for r in res:\n",
    "        print(r)\n",
    "except Exception as e:\n",
    "    error(check_q2, e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Note: The try and except block was altered to return 'None' after it was determined that the requested data does not exists within our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query 3\n",
    "\n",
    "**Requirement**: Returns every user name (first and last) in my music app history who listened to the song 'All Hands Against His Own'\n",
    "\n",
    "**Description:** For this query, we'll PRIMARY KEY from a combination the 'song' and 'userId' columns. 'song' will be our PARTITIONING KEY. 'userId' will be our CLUSTERING KEY allowing query results to be sorted and returned in DESC order. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lines added: 6820\n",
      "Row(userid=29, lastname='Lynch', firstname='Jacqueline')\n",
      "Row(userid=80, lastname='Levine', firstname='Tegan')\n",
      "Row(userid=95, lastname='Johnson', firstname='Sara')\n"
     ]
    }
   ],
   "source": [
    "query = \"CREATE TABLE IF NOT EXISTS user_songs \\\n",
    "        (song text, lastName text, firstName text, userId int, \\\n",
    "        PRIMARY KEY (song, userId))\"\n",
    "\n",
    "try: \n",
    "    session.execute(query)\n",
    "except Exception as e:\n",
    "    error(query, e)\n",
    "    \n",
    "\n",
    "file = 'event_datafile_new.csv'\n",
    "line_ct = 0\n",
    "\n",
    "with open(file, encoding = 'utf8') as f:\n",
    "    csvreader = csv.reader(f)\n",
    "    next(csvreader) # skip header\n",
    "    for line in csvreader:\n",
    "        query = \"\"\"INSERT INTO user_songs (song, userId, lastName, firstName)\"\"\"\n",
    "        query = query + \"\"\" VALUES (%s, %s, %s, %s);\"\"\"\n",
    "        try: \n",
    "            session.execute(query, (line[9],int(line[10]), line[4], line[1]))\n",
    "            line_ct +=1\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "print(f\"lines added: {line_ct}\")\n",
    "\n",
    "check_q3 = \"\"\"SELECT userId, lastName, firstName from user_songs WHERE song = 'All Hands Against His Own';\"\"\"\n",
    "try: \n",
    "    res = session.execute(check_q3)\n",
    "except Exception as e:\n",
    "    error(check_q3, e)\n",
    "    \n",
    "for r in res:\n",
    "    print(r)\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop the tables before closing out the sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped tabled sessions\n",
      "Dropped tabled user_sessions\n",
      "Dropped tabled user_songs\n"
     ]
    }
   ],
   "source": [
    "tbl_ls = ['sessions', 'user_sessions', 'user_songs']\n",
    "\n",
    "for t in tbl_ls:\n",
    "    try: \n",
    "        session.execute(f\"DROP TABLE {t};\")\n",
    "        print(f\"Dropped tabled {t}\")\n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close the session and cluster connection¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "session.shutdown()\n",
    "cluster.shutdown()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources Used \n",
    "1. Casting data into the correct dtypes when executing a CQL statement : https://stackoverflow.com/questions/55290883/invalid-string-constant-error-in-apache-cassandra-using-python\n",
    "\n",
    "\n",
    "2. Handling empty ReturnSets: https://docs.datastax.com/en/developer/python-driver/3.25/api/cassandra/cluster/#cassandra.cluster.ResultSet\n",
    "\n",
    "\n",
    "\n",
    "3. Finding a better way to check that a give table has been created: https://docs.datastax.com/en/dse/5.1/cql/cql/cql_using/useQuerySystemTable.html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
